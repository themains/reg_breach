{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7194663-9bca-4021-b253-fade1be23a3d",
   "metadata": {},
   "source": [
    "### Concat all HIBP and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5db6b26-317f-4daf-9d5b-7e4d384b7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91243c96-1c4b-4337-a104-f9841ae748a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files:  85%|███████████████████████████████████████████████████████████████████████▌            | 989560/1162292 [21:53<02:34, 1116.48file/s]IOStream.flush timed out\n",
      "Processing JSON files: 100%|████████████████████████████████████████████████████████████████████████████████████| 1162292/1162292 [25:25<00:00, 761.83file/s]\n"
     ]
    }
   ],
   "source": [
    "# Directory path containing JSON files\n",
    "directory = 'pwned/'\n",
    "\n",
    "logging.basicConfig(filename='error_log_read_json.log', level=logging.ERROR,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Get list of JSON file paths in the directory\n",
    "json_files = glob.glob(directory + '/*.json')\n",
    "\n",
    "# Define a function for processing a JSON file\n",
    "def process_json_file(file):\n",
    "    try:\n",
    "        df = pd.read_json(file)\n",
    "        file_name = os.path.basename(file).rstrip('.json')\n",
    "        df['email'] = file_name\n",
    "        return df\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Error reading file: {file}. Error message: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create a pool of worker processes\n",
    "pool = Pool()\n",
    "\n",
    "# Create a progress bar with tqdm\n",
    "progress_bar = tqdm(total=len(json_files), desc=\"Processing JSON files\", unit=\"file\")\n",
    "\n",
    "# Process JSON files in parallel\n",
    "results = []\n",
    "for df in pool.imap_unordered(process_json_file, json_files):\n",
    "    results.append(df)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Close the pool of worker processes\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652c7b05-380b-4b7c-829c-d9a41926fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the list of DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(results, ignore_index=True)\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e170234-2316-4b26-b101-5b9cecb29220",
   "metadata": {},
   "outputs": [],
   "source": [
    "breaches = pd.read_json('data/breaches.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e037b515-8279-4413-a88a-491163fb3b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8643150, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breached_email_df = pd.merge(combined_df, breaches, on='Name')\n",
    "breached_email_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d785bbfc-e7ab-41ac-a5e9-80b878b2f738",
   "metadata": {},
   "source": [
    "### Let's create an email level dataset for which we have breaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6568e14-914f-4b02-916b-0b8646c257ab",
   "metadata": {},
   "source": [
    "#### Non-fab\n",
    "https://haveibeenpwned.com/FAQs#FabricatedBreach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a123c0e-ddb8-47f3-83d9-39d21920bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "breached_email_df['non_fab'] = ~breached_email_df['IsFabricated'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4142c6-d05f-47da-89ea-ed43c6b186b4",
   "metadata": {},
   "source": [
    "#### Serious Dataclasses Breached \n",
    "Either data that will help you hack your other accounts, e.g., Mother's Maiden Name, or sensitive personal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7c97c3-fc95-4be8-bae1-e74465de5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "serious_dataclasses = [\"Audio recordings\",\n",
    "\"Auth tokens\", #account cracking\n",
    "\"Bank account numbers\",\n",
    "\"Biometric data\",\n",
    "\"Browsing histories\",\n",
    "\"Chat logs\",\n",
    "\"Credit card CVV\", #fin\n",
    "\"Credit cards\", #fin\n",
    "#\"Credit status information\", # don't know what this means\n",
    "\"Drinking habits\",\n",
    "\"Driver's licenses\",\n",
    "\"Drug habits\",\n",
    "\"Email messages\",\n",
    "\"Encrypted keys\", #account cracking\n",
    "\"Government issued IDs\",\n",
    "#\"Health insurance information\",\n",
    "\"Historical passwords\", #account cracking\n",
    "\"HIV statuses\",\n",
    "#\"Mothers maiden names\", #account cracking\n",
    "\"Partial credit card data\", #fin\n",
    "\"Passport numbers\",\n",
    "\"Password hints\",\n",
    "\"Passwords\", #account cracking\n",
    "\"Personal health data\",\n",
    "\"Photos\",\n",
    "\"PINs\", #account cracking\n",
    "\"Places of birth\", #account cracking\n",
    "\"Private messages\",\n",
    "\"Security questions and answers\", #account cracking\n",
    "\"Sexual fetishes\",\n",
    "\"Sexual orientations\",\n",
    "\"SMS messages\",\n",
    "\"Social security numbers\",\n",
    "\"Taxation records\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544f4506-c21a-49c2-ad78-084a5b31a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "breached_email_df['serious'] = breached_email_df['DataClasses'].apply(lambda x: any(string in x for string in serious_dataclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900d65b-76bb-40cd-8b09-d88409656c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "br_email_df = breached_email_df.assign(count=1).\\\n",
    "    groupby('email').\\\n",
    "    agg(total_breaches = ('count', 'sum'),\n",
    "    serious_breaches   = ('serious', 'sum'),\n",
    "    non_fab_breaches   = ('non_fab', 'sum'),\n",
    "    non_null_uniques   = ('Name', 'nunique')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c11ade-cc44-44fb-9b7f-422ac4435aa5",
   "metadata": {},
   "source": [
    "### Join to Valid Email List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc66c78-1197-4235-ae0b-f39ca85c10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_emails = pd.read_csv(\"data/fl_valid_emails.csv\")\n",
    "# can also do less strict is_valid_email\n",
    "valid_emails = valid_emails[valid_emails['is_valid_email_dns'] == True] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fef74e-2994-4288-8231-8f046cd4c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge breaches to parsed\n",
    "valid_emails['email'] = valid_emails['email'].str.lower()\n",
    "br_email_df['email']  = br_email_df['email'].str.lower()\n",
    "fin_df = pd.merge(valid_emails, br_email_df, how = 'left', on = 'email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0f17e-72e6-4a04-9be0-bf97282143f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df.fillna({'total_breaches': 0, \n",
    "               'serious_breaches': 0,\n",
    "               'non_fab_breaches': 0,\n",
    "               'non_null_uniques': 0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f96b33-91b6-4860-b77f-ce5813a32801",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df[['total_breaches', 'serious_breaches', 'non_fab_breaches', 'non_null_uniques']].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572cf99-d55e-4d75-9a1a-5486bb90dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df[['total_breaches', 'serious_breaches', 'non_fab_breaches', 'non_null_uniques']].describe().to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5b8a8-3378-429c-8cd4-ecea4d3a3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fin_df['total_breaches'] > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff50550c-a52e-462a-8f28-b0188881e36c",
   "metadata": {},
   "source": [
    "### Digital Gap: Sociodemographic Predictors of Breaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7c56f-3abc-44f9-ad1b-8bf7e368a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_summary_statistics(data_df, groupby_column, value_column, percentiles=None):\n",
    "    \"\"\"\n",
    "    Calculate summary statistics for a given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data_df (DataFrame): The DataFrame containing the data.\n",
    "        groupby_column (str): The column to group by.\n",
    "        value_column (str): The column for which to calculate statistics.\n",
    "        percentiles (list, optional): List of percentiles to calculate. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with the summary statistics.\n",
    "    \"\"\"\n",
    "    if percentiles is None:\n",
    "        percentiles = [25, 50, 75]\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    summary_stats = data_df.groupby(groupby_column)[value_column].agg(['count', 'mean', 'std', 'min', 'max']).round(1)\n",
    "\n",
    "    # Calculate percentile values\n",
    "    percentile_values = data_df.groupby(groupby_column)[value_column].apply(lambda x: pd.Series(np.nanpercentile(x, percentiles), index=percentiles)).unstack().round(1)\n",
    "\n",
    "    # Merge summary statistics and percentile values\n",
    "    summary_with_percentiles = pd.merge(summary_stats, percentile_values, left_index=True, right_index=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    desired_columns = ['count', 'mean', 'std', 'min'] + percentiles + ['max']\n",
    "    summary_with_percentiles = summary_with_percentiles.reindex(columns=desired_columns).reset_index()\n",
    "\n",
    "    return summary_with_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3c3fa-07ef-4d76-8287-7ed63c60d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum = calculate_summary_statistics(fin_df, \n",
    "                                   groupby_column='gender', \n",
    "                                   value_column='total_breaches',\n",
    "                                   percentiles = [25, 50, 75])\n",
    "print(gen_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56a497-bfbf-4a4c-a14b-fdc68121ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sum.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5a893-0b67-4391-adff-f7085af46ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_sum = calculate_summary_statistics(fin_df, \n",
    "                                   groupby_column='race_lit', \n",
    "                                   value_column='total_breaches',\n",
    "                                   percentiles = [25, 50, 75])\n",
    "print(race_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06be44-368d-44ed-b277-be4be421e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_sum.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acd0ff-e533-4020-9422-ee6ac297de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Age\n",
    "\n",
    "fin_df['age'] = 2022 - pd.to_datetime(fin_df['birth_yr'], format='%m/%d/%Y').dt.year\n",
    "age_buckets = [0, 25, 50, 65, 120]\n",
    "labels = ['<25', '25--50', '50--65', '65+'] \n",
    "\n",
    "fin_df['age_lab'] = pd.cut(fin_df['age'], bins = age_buckets, labels = labels)\n",
    "fin_df['age_lab'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd95008-3484-43b1-a981-614bab72e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_summary_statistics(fin_df, \n",
    "                                   groupby_column='age_lab', \n",
    "                                   value_column='total_breaches',\n",
    "                                   percentiles = [25, 50, 75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abe06b-4056-4935-9487-b815f86b10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "lowess = sm.nonparametric.lowess\n",
    "\n",
    "lowess_model = lowess(fin_df['total_breaches'], fin_df['age'], frac=0.07)\n",
    "\n",
    "# Create the plot using seaborn and matplotlib\n",
    "sns.set_style(\"whitegrid\")  # Set the plot style\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lowess_model[:, 0], lowess_model[:, 1], color='red', linewidth=2, label='Lowess Smoothed')\n",
    "\n",
    "plt.xlabel('Age', fontsize=14)\n",
    "plt.ylabel('Total Breaches', fontsize=14)\n",
    "plt.title('Lowess Smoothed Plot', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Adjust tick label sizes\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(MultipleLocator(base=10))\n",
    "plt.xlim(min(fin_df['age']), max(fin_df['age']))\n",
    "\n",
    "# Add a light gray background to the plot\n",
    "plt.gca().set_facecolor('#f0f0f0')\n",
    "\n",
    "# Remove right and top spines\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figs/age_breaches.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbe4ac-9394-4c4b-afac-e7a0f0811eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's winsorize or we can lowess over medians\n",
    "from scipy.stats.mstats import winsorize\n",
    "winsorized_breaches = winsorize(fin_df['total_breaches'], limits=(0.0, 0.2))\n",
    "\n",
    "lowess_model = lowess(winsorized_breaches, fin_df['age'], frac=0.07)\n",
    "\n",
    "# Create the plot using seaborn and matplotlib\n",
    "sns.set_style(\"whitegrid\")  # Set the plot style\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lowess_model[:, 0], lowess_model[:, 1], color='red', linewidth=2, label='Lowess Smoothed')\n",
    "\n",
    "plt.xlabel('Age', fontsize=14)\n",
    "plt.ylabel('Total Breaches (Winsorized)', fontsize=14)\n",
    "plt.title('Lowess Smoothed Plot', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Adjust tick label sizes\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(MultipleLocator(base=10))\n",
    "plt.xlim(min(fin_df['age']), max(fin_df['age']))\n",
    "\n",
    "# Add a light gray background to the plot\n",
    "plt.gca().set_facecolor('#f0f0f0')\n",
    "\n",
    "# Remove right and top spines\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figs/age_winsorized_breaches.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d63fb-b422-41c8-b675-b87230298f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
